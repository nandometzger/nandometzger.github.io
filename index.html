<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1.0"> -->

    <title>Nando Metzger</title>

    <meta name="author" content="Nando Metzger">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="shortcut icon" href="assets/images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5FBRP8LCRB"></script>
  <script>
    window.dataLayer = window.dataLayer || []; 
    function gtag() {
      dataLayer.push(arguments);
    } 
    gtag('js', new Date()); 
    gtag('config', 'G-5FBRP8LCRB');
  </script>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Nando Metzger
                </p>
                <p>
                  I am a PhD student in the
                  <a style="display:inline" href="https://prs.igp.ethz.ch/">Photogrammetry and Remote Sensing Lab, ETH Zürich</a>
                  My supervisors are 
                  <a style="display:inline" href="https://scholar.google.ch/citations?user=FZuNgqIAAAAJ&hl=en">Prof. Konrad Schindler</a>
                  and 
                  <a style="display:inline" href="https://scholar.google.com/citations?user=p3iJiLIAAAAJ&hl=en">Prof. Devis Tuia</a>.
                  I am collaborating with the ICRC to map vulnerable populations in developing countries.
                  I previously interned at <a style="display:inline" href="https://about.meta.com/realitylabs/">Meta's Reality Labs Research</a>, with which I am currently collaborating with.
                </p>
                <p> 
                  I obtained my bachelor and master's degree in Geomatics Engineering from ETH Zürich. During my master's 
                  specialized in deep learning, computer vision and remote sensing.
                </p>
                <p style="text-align:center">
                  <a href="mailto:nando.metzger@geod.baug.ethz.ch">Email</a> &nbsp;/&nbsp; 
                  <a href="https://scholar.google.ch/citations?hl=en&user=pGqbcuIAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/nando-metzger-68aa0518b/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/nandometzger">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/nandometzger/">Github</a> &nbsp;/&nbsp;
                  <a href="https://medium.com/@nandometzger">Medium</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="./assets/images/Nando_Portrait.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="./assets/images/Nando_Portrait.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="25">
            <tr> 
              <td width="12%" valign="middle">
                <a href="https://ethz.ch/en.html"><img style="width:100%;max-width:100%;object-fit: cover;" src="assets/images/eth_logo.png"></a>
              </td>
              <td width="12%" valign="middle">
                <a href="https://prs.igp.ethz.ch/"><img style="width:100%;max-width:100%;object-fit: cover;" src="assets/images/prslogo_only.jpg""></a>
              </td>
              <td width="12%" valign="middle">
                <a href="https://about.meta.com/"><img style="width:100%;max-width:100%;object-fit: cover;" src="assets/images/meta_logo.png"></a>
              </td>
              <td width="5%" valign="middle">
                <a href="https://about.meta.com/"><img style="width:100%;max-width:100%;object-fit: cover;" src="assets/images/Reality_Labs_logo.svg.png"></a>
              </td> 
            </tr>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>News</h2>
                  <ul>
                    <li>17th - 21st of June 2024: I'm attending <a href="https://cvpr.thecvf.com/Conferences/2024">CVPR 2024</a> in Seattle, WA, USA presenting Marigold.</li>
                    <li>25th of April: Invited talk about my population mapping projects at <a href="https://www.worldpop.org/">WorldPop</a> in Southampton, UK.</li>
                    <li>December 2023 - February 2024: I'm interning at Meta's Reality Labs in Redmond, WA, USA.</li>
                    <li>22nd of September 2023: Invited talk at UZH Astrophysics Seminar. <a href="https://www.youtube.com/watch?v=0Mq7OUHbfow">Recording</a> </li>
                    <li>4th - 6th of September 2023: I'm attending the <a href="https://swiss-remote-sensing-days.github.io/">Swiss Remote Sensing Days 2023</a> in St. Gallen, CH. </li>
                    <li>15th of August 2023: Invited talk at Google's Semantic perception group.</li>
                    <li>10th of August 2023: Invited talk at Google's Open Building team.</li>
                    <li>1st of July 2023: Invited talk at <a href="https://socialincome.org/">SocialIncome</a> to present the POMELO project. </li>
                    <li>18th - 22nd of June 2023: I am attending <a href="https://cvpr.thecvf.com/Conferences/2023">CVPR 2023</a> in Vancouver, Canada presenting DADA.</li>
                    <li>13th of March: Visiting the ICRC headquarters in Geneva, CH.</li>
                    <li>13th of March: Invited talk about POMELO at the SDG lab workshop at Deloitte in Geneva, CH.</li>
                    <li>30th of November 2022: Invited talk at ETH's Weather and Climate Risks group.</li>
                    <li>14th of October 2022: Invited talk at the <a href="https://ai.ethz.ch/industry/AIplusX/aixsummit22.html">ETH's AI+X event </a>, presenting POMELO.</li>
                    <li>28th of June - 1st of July 2022: I'm at the Machine Learning Summer School in Krakow, Poland. </li>
                    <li>23rd - 27th of May 2022: I'm attending <a href="https://earth.esa.int/eogateway/events/living-planet-symposium-2022">ESA's Living Planet Symposium</a> in Bonn, DE.</li>
                    <li>1st - 4th of May 2022: I'm attending the <a href="https://www.epfl.ch/research/domains/eo/events-and-news/srsd-2022/">Swiss Remote Sensing Days 2022</a> in Ascona, CH.</li>
                    <li>1st of September 2021: I started my PhD at the <a href="https://prs.igp.ethz.ch/">Photogrammetry and Remote Sensing Lab at ETH Zurich.</a> </li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody> -->

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, deep learning, and their applications to remote sensing.
                  Most of my work is related to super-resolution, depth estimation or both at the same time.
                  Some papers are <span class="highlight">highlighted</span>. * indicates equal contribution.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>




    <tr onmouseout="marigold_stop()" onmouseover="marigold_start()" bgcolor="#c7eaf2">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='marigold_image'><video  width=100% height=100% muted autoplay loop>
          <source src="assets/images/marigold_rec.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='assets/images/splashdog_sq.png' width="160">
        </div>
        <script type="text/javascript">
          function marigold_start() {
            document.getElementById('marigold_image').style.opacity = "1";
          }

          function marigold_stop() {
            document.getElementById('marigold_image').style.opacity = "0";
          }
          marigold_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://marigoldmonodepth.github.io/">
			<span class="papertitle">Marigold: Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation
</span>
        </a>
        <br>
				<a href="http://www.kebingxin.com/">Bingxin Ke</a>,
        <a href="https://www.obukhov.ai/">Anton Obukhov</a>, 
        <a href="https://shengyuh.github.io/">Shengyu Huang</a>,
        <strong>Nando Metzger</strong>, 
				<a href="https://rcdaudt.github.io/">Rodrigo Caye Daudt</a>, 
        <a href="https://scholar.google.com/citations?user=FZuNgqIAAAAJ&hl=en">Konrad Schindler</a>, 

        <br>
        <em>CVPR</em>, 2024 &nbsp <font color="red"><strong>(Oral, Best Paper Candidate)</strong></font>
        <br>
        <a href="https://marigoldmonodepth.github.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2312.02145">arXiv</a>
        /
        <a href="https://github.com/prs-eth/marigold">code</a>
        /
        <a href="https://colab.research.google.com/drive/12G8reD13DdpMie5ZQlaFNo2WCGeNUH-u?usp=sharing">colab</a>
        /
        <a href="https://huggingface.co/spaces/prs-eth/marigold-lcm">demo</a>
        <p></p>
        <p>
          Marigold is an affine-invariant monocular depth estimation method based on Stable Diffusion,
          leveraging its rich prior knowledge for better generalization and achieving state-of-the-art performance with significant improvements,
           even with synthetic training data.
        </p>
      </td>
    </tr>


    

    <tr onmouseout="thera_stop()" onmouseover="thera_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='thera_image'><video  width=100% height=100% muted autoplay loop>
          <source src="assets/images/thera_rec.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='assets/images/thera.png' width="160">
        </div>
        <script type="text/javascript">
          function thera_start() {
            document.getElementById('thera_image').style.opacity = "1";
          }

          function thera_stop() {
            document.getElementById('thera_image').style.opacity = "0";
          }
          thera_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://github.com/prs-eth/thera">
			<span class="papertitle">Thera: Neural Fields with Thermal Activations for Arbitrary-Scale Super-Resolution
</span>
        </a>
        <br>
				<a href="https://github.com/alebeck">Alexander Becker</a>*, 
				<a href="https://rcdaudt.github.io/">Rodrigo Caye Daudt</a>*, 
        <strong>Nando Metzger</strong>, 
        <a href="https://scholar.google.ch/citations?user=sxLG1rgAAAAJ&hl=en">Jan Dirk Wegner</a>, 
        <a href="https://scholar.google.com/citations?user=FZuNgqIAAAAJ&hl=en">Konrad Schindler</a>, 
        <br>
        <em>arXiv</em>, 2023
        <br> 
        <a href="https://arxiv.org/abs/2311.17643">arXiv</a>
        /
        <a href="https://github.com/prs-eth/thera">code</a>
        <p></p>
        <p>
          We present a novel approach for arbitrary-scale single image super-resolution (ASSR) that uses neural fields with an adaptive Gaussian point spread function (PSF) to prevent aliasing and achieve superior results,
          offering more parameter efficiency and setting a new state of the art while maintaining computational efficiency.
        </p>
      </td>
    </tr>


    <tr onmouseout="popcorn_stop()" onmouseover="popcorn_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='popcorn_image'><video  width=100% muted autoplay loop>
          <source src="assets/images/popcorn_rec.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='assets/images/popcorn_preview.png' width=100%>
        </div>
        <script type="text/javascript">
          function popcorn_start() {
            document.getElementById('popcorn_image').style.opacity = "1";
          }

          function popcorn_stop() {
            document.getElementById('popcorn_image').style.opacity = "0";
          }
          popcorn_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://creiser.github.io/binary_opacity_grid/">
          <span class="papertitle">POPCORN: High-resolution Population Maps Derived from Sentinel-1 and Sentinel-2
</span>
        </a>
        <br>
        <strong>Nando Metzger</strong>, 
				<a href="https://rcdaudt.github.io/">Rodrigo Caye Daudt</a>, 
        <a href="https://scholar.google.com/citations?user=p3iJiLIAAAAJ&hl=en">Devis Tuia</a> 
        <a href="https://scholar.google.com/citations?user=FZuNgqIAAAAJ&hl=en">Konrad Schindler</a>, 
        <br>
        <em>arXiv</em>, 2023
        <br>
        <a href="https://popcorn-population.github.io/">project page</a>
        /
        <a href="https://github.com/prs-eth/popcorn">code</a>
        /
        <a href="https://arxiv.org/abs/2311.14006">arXiv</a>
        /
        <a href="https://ee-nandometzger.projects.earthengine.app/view/popcornv1-rwa">demo</a>
        /
        <a href="https://code.earthengine.google.com/f90c3d3a77ec4dcfeb645457a87ddf48">data</a>
        <p></p>
        <p>
          POPCORN is a lightweight population mapping method using free satellite images and minimal data,
          surpassing existing accuracy and providing interpretable maps for mapping populations in data-scarce regions.
        </p>
      </td>
    </tr>

    <tr onmouseout="dada_stop()" onmouseover="dada_start()" bgcolor="#c7eaf2">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='dada_image'><video  width=100% muted autoplay loop>
          <source src="assets/images/diffusion_vid.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='assets/images/dada_sq.png' width=100%>
        </div>
        <script type="text/javascript">
          function dada_start() {
            document.getElementById('dada_image').style.opacity = "1";
          }

          function dada_stop() {
            document.getElementById('dada_image').style.opacity = "0";
          }
          dada_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Metzger_Guided_Depth_Super-Resolution_by_Deep_Anisotropic_Diffusion_CVPR_2023_paper.html">
          <span class="papertitle">DADA: Guided Depth Super-Resolution by Deep Anisotropic Diffusion</span>
        </a>
        <br>
		      <strong>Nando Metzger</strong>*, 
				  <a href="https://rcdaudt.github.io/">Rodrigo Caye Daudt</a>*, 
          <a href="https://scholar.google.com/citations?user=FZuNgqIAAAAJ&hl=en">Konrad Schindler</a>, 
        <br>
        <em>CVPR</em>, 2023
        <br>
        <a href="https://arxiv.org/abs/2211.11592">arXiv</a>
        /
        <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Metzger_Guided_Depth_Super-Resolution_by_Deep_Anisotropic_Diffusion_CVPR_2023_paper.html">paper</a>
        /
        <a href="https://rcdaudt.github.io/dada/">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=7RgXJz_3kcg">video</a>
        /
        <a href="assets/images/DADA_poster.pdf">poster</a>
        <p></p>
        <p>
          We propose DADA, a novel approach to depth image super-resolution by combining guided anisotropic diffusion with a deep convolutional network, enhancing both edge detail and contextual reasoning.
          This method achieves unprecedented results in three benchmarks, especially at larger scales like x32
        </p>
      </td>
    </tr>
	

    <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
          <source src="assets/images/marigold_reXc.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='assets/images/pomelo_map2.png' width=100%>
        </div>
        <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://pratulsrinivasan.github.io/nuvo/">
          <span class="papertitle">POMELO: Fine-grained Population Mapping from Coarse Census Counts and Open Geodata</span>
        </a>
        <br>
        	<strong>Nando Metzger</strong>,
				  <a href="https://scholar.google.com.br/citations?user=xbCWyaoAAAAJ&hl=en">John E Vargas-Muñoz</a>, 
				  <a href="https://rcdaudt.github.io/">Rodrigo Caye Daudt</a>, 
				  <a href="https://bkellenb.github.io/">Benjamin Kellenberger</a>,  
          Thao Ton-That Whelan,
          <a href="https://mimran.me/">Muhammad Imran</a>, 
          <a href="https://www.ferdaofli.com/">Ferda Ofli</a>, 
          <a href="https://scholar.google.com/citations?user=FZuNgqIAAAAJ&hl=en">Konrad Schindler</a>, 
          <a href="https://scholar.google.com/citations?user=p3iJiLIAAAAJ&hl=en">Devis Tuia</a>
        <br>
        <em>Nature - Scientific Reports</em>, 2022
        <br>
        <a href="https://pratulsrinivasan.github.io/nuvo/">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=hmJiOSTDQZI">video</a>
        /
        <a href="http://arxiv.org/abs/2312.05283">arXiv</a>
        <p></p>
        <p>
          POMELO is a deep learning model that creates fine-grained population maps using coarse census counts and open geodata,
          achieving high accuracy in sub-Saharan Africa and effectively estimating population numbers even without any census data.
        </p>
      </td>
    </tr>


    <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
          <source src="assets/images/marigold_reXc.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='assets/images/forecasting.png' width=100%>
        </div>
        <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://link.springer.com/article/10.1007/s41064-023-00258-8">
          <span class="papertitle">Urban Change Forecasting from Satellite Images</span>
        </a>
        <br>
        	<strong>Nando Metzger</strong>,
          <a href="https://scholar.google.com/citations?user=rJpIyQUAAAAJ&hl=en">Mehmet Ozgur Turkoglu</a>
				  <a href="https://rcdaudt.github.io/">Rodrigo Caye Daudt</a>, 
          <a href="https://scholar.google.ch/citations?user=sxLG1rgAAAAJ&hl=en">Jan Dirk Wegner</a>, 
          <a href="https://scholar.google.com/citations?user=FZuNgqIAAAAJ&hl=en">Konrad Schindler</a>,
        <br>
        <em>PFG</em>, 2022, &nbsp <font color="red"><strong>(Karl-Kraus Best Paper Award)</strong></font>
        <br>
        <a href="https://link.springer.com/article/10.1007/s41064-023-00258-8">paper</a> 
        <p></p>
        <p>
          We propose a method for forecasting the emergence and timing of new buildings using a deep neural network with a custom pretraining procedure, validated on the SpaceNet7 dataset.
        </p>
      </td>
    </tr>

    
    <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
          <source src="assets/images/marigold_reXc.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='assets/images/ODERNN.png' width=100%>
        </div>
        <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://link.springer.com/article/10.1007/s41064-023-00258-8">
          <span class="papertitle">Crop Classification under Varying Cloud Cover with Neural Ordinary Differential Equations</span>
        </a>
        <br>
        	<strong>Nando Metzger</strong>*,
				  <a href="https://scholar.google.com/citations?user=rJpIyQUAAAAJ&hl=en">Mehmet Ozgur Turkoglu</a>*,
          <a href="https://scholar.google.it/citations?user=vLYzYl4AAAAJ&hl=it">Stefano D'Aronco</a>,
          <a href="https://scholar.google.ch/citations?user=sxLG1rgAAAAJ&hl=en">Jan Dirk Wegner</a>,
          <a href="https://scholar.google.com/citations?user=FZuNgqIAAAAJ&hl=en">Konrad Schindler</a>,
        <br>
        <em>IEEE, TGRS</em>, 2021,
        <br>
        <a href="https://link.springer.com/article/10.1007/s41064-023-00258-8">paper</a> 
        <p></p>
        <p>
          We propose using neural ordinary differential equations (NODEs) combined with RNNs to improve crop classification from irregularly spaced satellite images,
          showing enhanced accuracy over common methods, especially with few observations,
          and better early-season forecasting due to the continuous representation of latent dynamics.
        </p>
      </td>
    </tr>

    <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
          <source src="assets/images/marigold_reXc.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='assets/images/DSMref.png' width=100%>
        </div>
        <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2012.07427">
          <span class="papertitle">DSM Refinement with Deep Encoder-Decoder Networks</span>
        </a>
        <br>
        	<strong>Nando Metzger</strong>,
          <a href="https://scholar.google.ch/citations?user=P-op4CgAAAAJ&hl=de">Corinne Stucker</a>,
          <a href="https://scholar.google.com/citations?user=FZuNgqIAAAAJ&hl=en">Konrad Schindler</a>,
        <br>
        <em>arXiv</em>, 2020,
        <br>
        <a href="https://arxiv.org/abs/2012.07427">paper</a> 
        <p></p>
        <p>

          This work presents a method for automatically refining 3D city models generated from aerial images by using a neural network trained with reference data and a loss function to improve DSMs,
          effectively preserving geometric structures while removing noise and artifacts.
        </p>
      </td>
    </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Thank you for the template <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
